<!doctype html>
<html lang="en">


<!-- === Header Starts === -->
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>FairGen</title>

  <link href="./assets/bootstrap.min.css" rel="stylesheet">
  <link href="./assets/font.css" rel="stylesheet" type="text/css">
  <link href="./assets/style.css" rel="stylesheet" type="text/css">
</head>
<!-- === Header Ends === -->


<body>


<!-- === Home Section Starts === -->
<div class="section">
  <!-- === Title Starts === -->
  <div class="header">
    <div class="logo">
      <a href="https://genforce.github.io/" target="_blank"><img src="./assets/genforce.png"></a>
    </div>
    <div class="title", style="padding-top: 10pt;">
      Improving the Fairness of Deep Generative Models
      <br>
      without Retraining
    </div>
  </div>
  <!-- === Title Ends === -->
  <div class="author">
    <a href="https://ariostgx.github.io/website/" target="_blank">Shuhan Tan</a><sup>1</sup>,&nbsp;
    <a href="http://shenyujun.github.io/" target="_blank">Yujun Shen</a><sup>2</sup>,&nbsp;
    <a href="http://bzhou.ie.cuhk.edu.hk" target="_blank">Bolei Zhou</a><sup>2</sup>
  </div>
  <div class="institution">
    <sup>1</sup> Sun Yat-sen University <br>
    <sup>2</sup> The Chinese University of Hong Kong <br>
  </div>
  <div class="link">
    <a href="https://arxiv.org/pdf/2012.04842.pdf" target="_blank">[Paper]</a>&nbsp;
    <a href="https://github.com/genforce/fairgen" target="_blank">[Code]</a>
    <a href="https://colab.research.google.com/drive/1_k45KPpLP0xMqC8AjmUFerqdDCbkwN1l?usp=sharing" target="_blank">[Colab]</a>
  </div>
  <div class="teaser">
    <img src="./assets/framework.jpg">
  </div>
</div>
<!-- === Home Section Ends === -->


<!-- === Overview Section Starts === -->
<div class="section">
  <div class="title">Overview</div>
  <div class="body">
    We propose a simple yet effective method to improve the <i>fairness</i> of image generation for a pre-trained GAN model <i>without retraining</i>.
    Generative Adversarial Networks (GANs) have recently advanced face synthesis by learning the underlying distribution of observed data.
    However, it will lead to a <i>biased</i> image generation due to the imbalanced training data or the mode collapse issue.
    This work utilizes the recent <i>GAN interpretation method</i> and a <i>Gaussian Mixture Model (GMM)</i> to support the sampling of latent codes for producing images with a more fair attribute distribution.
    We call this method <i>FairGen</i>.
    Experiments show that <i>FairGen</i> can substantially improve the fairness of image generation. The images generated from our method are further applied to reveal and quantify the biases in <i>commercial face classifiers</i> and <i>face super-resolution</i> model.


  </div>
</div>
<!-- === Overview Section Ends === -->


<!-- === Result Section Starts === -->
<div class="section">
  <div class="title">Results</div>
  <div class="body">
    Notice that all the following images are synthesized by StyleGAN v2. 
    <p style="margin-top: 10pt; text-align:center; font-size:25px; font-weight:bold">Fair Image Generation<p>

    <p style="margin-top: 10pt; margin-bottom: 5pt;">Age - Eyeglasses</p>
    <img src="./assets/age_eyeglasses.jpg" width="100%">

    <p style="margin-top: 10pt; margin-bottom: 5pt;">Gender - Black Hair</p>
    <img src="./assets/gender_black_hair.jpg" width="100%">

    <p style="margin-top: 10pt; text-align:center; font-size:25px; font-weight:bold">Identifying Bias in Existing Models<p>

    <p style="margin-top: 10pt; margin-bottom: 5pt;">Mis-classified Images by Commercial APIs</p>
    <img src="./assets/api.jpg" width="100%">

    <p style="margin-top: 10pt; margin-bottom: 5pt;">Attribute Alternation by a Face Super-resolution Model</p>
    <img src="./assets/PULSE.jpg" width="100%">
  </div>
</div>
<!-- === Result Section Ends === -->


<!-- === Reference Section Starts === -->
<div class="section">
  <div class="bibtex">BibTeX</div>
<pre>
@article{tan2020fairgen,
  title   = {Improving the Fairness of Deep Generative Models without Retraining},
  author  = {Tan, Shuhan and Shen, Yujun and Zhou, Bolei},
  journal = {arXiv preprint arXiv:2012.04842},
  year    = {2020}
}
</pre>

  <div class="ref">Related Work</div>
  <div class="citation">
    <div class="image"><img src="./assets/stylegan.jpg"></div>
    <div class="comment">
      <a href="https://github.com/NVlabs/stylegan" target="_blank">
        T. Karras, S. Laine, T. Aila.
        A Style-Based Generator Architecture for Generative Adversarial Networks.
        CVPR 2019.</a><br>
      <b>Comment:</b>
      Proposes style-based generator for high-quality image synthesis.
    </div>
  </div>

   <div class="citation">
    <div class="image"><img src="./assets/zhao2018empirical.jpg" height="500" ></div>
    <div class="comment">
      <a href="https://proceedings.neurips.cc/paper/2018/hash/5317b6799188715d5e00a638a4278901-Abstract.html" target="_blank">
        S. Zhao, H. Ren, A. Yuan, J. Song, N. Goodman, S. Ermon.
        Bias and Generalization in Deep Generative Models: An Empirical Study.
        NeurIPS 2018.</a><br>
      <b>Comment:</b>
      Gives a empirical study on the bias and generalization introduced by the training process of deep generative models.
    </div>
  </div>

  <div class="citation">
    <div class="image"><img src="./assets/choi2020fair.jpg" height="500" ></div>
    <div class="comment">
      <a href="http://proceedings.mlr.press/v119/choi20a.html" target="_blank">
        K. Choi, A. Grover, T. Singh, R. Shu, S. Ermon.
        Fair Generative Modeling via Weak Supervision.
        ICML 2020.</a><br>
      <b>Comment:</b>
      Offsets the bias in GAN by learning a weighting function to reweight the importance of each instance during GAN training.
    </div>
  </div>

  <div class="citation">
    <div class="image"><img src="./assets/inclusiveGAN.jpg" height="500" ></div>
    <div class="comment">
      <a href="https://arxiv.org/abs/2004.03355" target="_blank">
        N. Yu, K. Li, P. Zhou, J. Malik, L. Davis, M. Fritz
        Inclusive GAN: Improving Data and Minority Coverage in Generative Models.
        ECCV 2020.</a><br>
      <b>Comment:</b>
      Mitigates GAN bias by encouraging data coverage during the training with new objective functions.
    </div>
  </div>

  <div class="citation">
    <div class="image"><img src="./assets/interfacegan.jpg"></div>
    <div class="comment">
      <a href="https://genforce.github.io/interfacegan/" target="_blank">
        Y. Shen, J. Gu, X. Tang, B. Zhou.
        Interpreting the Latent Space of GANs for Semantic Face Editing.
        CVPR 2020.</a><br>
      <b>Comment:</b>
      Interprets the face semantics emerging in the latent space of GANs with the help of off-the-shelf classifiers.
    </div>
  </div>


</div>
<!-- === Reference Section Ends === -->


</body>
</html>
